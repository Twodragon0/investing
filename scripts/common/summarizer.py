"""Keyword-based theme summarizer for collected news items.

Classifies news items into predefined themes using keyword matching
and generates markdown summary sections including:
- Issue distribution ASCII bar chart
- Theme-based news grouping with articles per theme
- Top keyword analysis

No LLM or external dependencies required.
"""

import re
import logging
from collections import Counter
from typing import List, Dict, Any, Tuple

logger = logging.getLogger(__name__)

# Theme definitions: (theme_name_ko, theme_key, emoji, keywords)
THEMES = [
    ("Í∑úÏ†ú/Ï†ïÏ±Ö", "regulation", "üîµ", [
        "sec", "cftc", "fca", "regulation", "regulatory", "compliance",
        "Í∑úÏ†ú", "Í∏àÏúµÏúÑ", "Í∏àÍ∞êÏõê", "mica", "esma", "mas", "Î≤ïÏïà", "bill",
        "enforcement", "lawsuit", "ÏÜåÏÜ°", "Ï†úÏû¨",
    ]),
    ("DeFi", "defi", "üü£", [
        "defi", "dex", "yield", "lending", "tvl", "liquidity",
        "aave", "uniswap", "compound", "staking",
        "restaking", "bridge", "swap", "pool", "vault",
    ]),
    ("ÎπÑÌä∏ÏΩîÏù∏", "bitcoin", "üü†", [
        "bitcoin", "btc", "mining", "halving", "ÎπÑÌä∏ÏΩîÏù∏", "Ï±ÑÍµ¥",
        "satoshi", "lightning network",
        "ordinals", "runes", "etf",
    ]),
    ("Ïù¥ÎçîÎ¶¨ÏõÄ", "ethereum", "üî∑", [
        "ethereum", "eth", "layer2", "rollup", "Ïù¥ÎçîÎ¶¨ÏõÄ",
        "solidity", "evm", "l2",
        "blob", "dencun", "arbitrum", "optimism", "base", "zksync",
    ]),
    ("AI/Í∏∞Ïà†", "ai_tech", "ü§ñ", [
        "ai", "artificial intelligence", "gpu", "Ïù∏Í≥µÏßÄÎä•",
        "machine learning", "chatgpt", "nvidia", "Î∞òÎèÑÏ≤¥",
        "ÏóîÎπÑÎîîÏïÑ", "ÌÖåÏä¨Îùº", "Ïï†Ìîå", "ÎßàÏù¥ÌÅ¨Î°úÏÜåÌîÑÌä∏", "Íµ¨Í∏Ä",
        "openai", "anthropic", "semiconductor", "tsmc",
    ]),
    ("Îß§ÌÅ¨Î°ú/Í∏àÎ¶¨", "macro", "üìä", [
        "fed", "interest rate", "inflation", "Í∏àÎ¶¨", "ÌïúÍµ≠ÏùÄÌñâ",
        "gdp", "cpi", "fomc", "rate cut", "rate hike", "ÌôòÏú®",
        "Î¨ºÍ∞Ä", "Ïã§ÏóÖÎ•†", "Í≥†Ïö©", "ÏÜåÎπÑÏûêÎ¨ºÍ∞Ä", "pce",
        "Í∏∞Ï§ÄÍ∏àÎ¶¨", "ÏñëÏ†ÅÏôÑÌôî", "ÏñëÏ†ÅÍ∏¥Ï∂ï", "treasury", "Ï±ÑÍ∂å",
    ]),
    ("Í±∞ÎûòÏÜå", "exchange", "üè¶", [
        "binance", "coinbase", "exchange", "listing", "Í±∞ÎûòÏÜå",
        "upbit", "bithumb", "bybit", "okx",
        "kraken", "ÏÉÅÏû•", "ÏÉÅÏû•ÌèêÏßÄ", "delisting",
    ]),
    ("Î≥¥Ïïà/Ìï¥ÌÇπ", "security", "üî¥", [
        "hack", "exploit", "vulnerability", "security", "Ìï¥ÌÇπ",
        "breach", "phishing", "scam", "rug pull",
        "drain", "flash loan", "oracle", "Ïû¨ÏßÑÏûÖ",
    ]),
    ("Ï†ïÏπò/Ï†ïÏ±Ö", "politics", "üèõÔ∏è", [
        "trump", "Ïù¥Ïû¨Î™Ö", "election", "policy", "Ï†ïÏ±Ö",
        "tariff", "sanction", "congress", "ÏùòÌöå", "Í¥ÄÏÑ∏",
        "Î∞±ÏïÖÍ¥Ä", "ÎåÄÌÜµÎ†π", "executive order", "ÌñâÏ†ïÎ™ÖÎ†π",
    ]),
    ("NFT/Web3", "nft_web3", "üé®", [
        "nft", "metaverse", "web3", "opensea", "Î©îÌÉÄÎ≤ÑÏä§",
        "digital collectible",
        "gamefi", "socialfi", "creator",
    ]),
    ("Í∞ÄÍ≤©/ÏãúÏû•", "price_market", "üìà", [
        "price", "rally", "crash", "surge", "plunge", "ÏãúÏÑ∏",
        "ÏÉÅÏäπ", "ÌïòÎùΩ", "Í∏âÎì±", "Í∏âÎùΩ", "Ìè≠ÎùΩ", "Î∞òÎì±",
        "bull", "bear", "bullish", "bearish", "Í∞ïÏÑ∏", "ÏïΩÏÑ∏",
        "Ï°∞Ï†ï", "correction", "ÏΩîÏä§Ìîº", "ÏΩîÏä§Îã•", "ÎÇòÏä§Îã•",
        "Îã§Ïö∞Ï°¥Ïä§", "Í∏à", "ÏõêÏú†", "Îã¨Îü¨",
    ]),
]

TOP_THEMES_COUNT = 5
ARTICLES_PER_THEME = 5
BAR_WIDTH = 18

# Priority classification keywords
PRIORITY_KEYWORDS: Dict[str, List[str]] = {
    "P0": [
        "crash", "Ìè≠ÎùΩ", "hack", "Ìï¥ÌÇπ", "executive order", "ÌñâÏ†ïÎ™ÖÎ†π",
        "rate decision", "Í∏àÎ¶¨ Í≤∞Ï†ï", "ÌååÏÇ∞", "bankruptcy", "emergency",
        "Í∏¥Í∏â", "bank run", "Î±ÖÌÅ¨Îü∞", "exploit", "rug pull",
    ],
    "P1": [
        "regulation", "Í∑úÏ†ú", "etf", "approval", "fomc", "tariff", "Í¥ÄÏÑ∏",
        "earnings", "Ïã§Ï†Å", "sanctions", "Ï†úÏû¨", "indictment", "Í∏∞ÏÜå",
        "sec filing", "listing", "ÏÉÅÏû•", "delisting", "ÏÉÅÏû•ÌèêÏßÄ",
    ],
    "P2": [
        "partnership", "upgrade", "launch", "airdrop", "report",
        "update", "integration", "collaboration", "Ï†úÌú¥", "Ï∂úÏãú",
        "ÏóÖÍ∑∏Î†àÏù¥Îìú", "ÏóêÏñ¥ÎìúÎ°≠", "Î¶¨Ìè¨Ìä∏",
    ],
}


class ThemeSummarizer:
    """Classify news items into themes and generate markdown summary sections."""

    def __init__(self, items: List[Dict[str, Any]]):
        self.items = items
        self._theme_scores: Dict[str, int] = {}
        self._theme_articles: Dict[str, List[Dict[str, Any]]] = {}
        self._scored = False

    def _ensure_scored(self):
        """Score themes lazily on first access."""
        if self._scored:
            return
        self._score_themes()
        self._scored = True

    def _score_themes(self):
        """Score each theme by keyword frequency across all items."""
        all_text = " ".join(
            (item.get("title", "") + " " + item.get("description", ""))
            for item in self.items
        ).lower()

        token_freq = Counter(re.findall(r"[a-zÍ∞Ä-Ìû£]+", all_text))

        for theme_name, theme_key, _emoji, keywords in THEMES:
            score = sum(token_freq.get(kw, 0) for kw in keywords)
            for kw in keywords:
                if " " in kw:
                    score += all_text.count(kw)
            self._theme_scores[theme_key] = score

        # Match articles to themes (each article to its best-matching theme)
        article_assigned: Dict[int, str] = {}
        for theme_name, theme_key, _emoji, keywords in THEMES:
            matched = []
            kw_set = set(keywords)
            for idx, item in enumerate(self.items):
                item_text = (item.get("title", "") + " " + item.get("description", "")).lower()
                if any(kw in item_text for kw in kw_set):
                    matched.append(item)
                    if idx not in article_assigned:
                        article_assigned[idx] = theme_key
            self._theme_articles[theme_key] = matched

    def get_top_themes(self) -> List[Tuple[str, str, str, int]]:
        """Return top themes as (name, key, emoji, article_count) tuples."""
        self._ensure_scored()
        theme_lookup = {key: (name, emoji) for name, key, emoji, _ in THEMES}
        ranked = sorted(self._theme_scores.items(), key=lambda x: x[1], reverse=True)
        result = []
        for key, score in ranked:
            if score <= 0:
                continue
            name, emoji = theme_lookup.get(key, (key, ""))
            count = len(self._theme_articles.get(key, []))
            if count > 0:
                result.append((name, key, emoji, count))
            if len(result) >= TOP_THEMES_COUNT:
                break
        return result

    def classify_priority(self) -> Dict[str, List[Dict[str, Any]]]:
        """Classify items into priority buckets (P0, P1, P2).

        Returns dict with keys "P0", "P1", "P2" mapping to lists of items.
        Items are matched by keyword presence in title + description.
        Each item is assigned to only its highest priority bucket.
        """
        result: Dict[str, List[Dict[str, Any]]] = {"P0": [], "P1": [], "P2": []}
        assigned: set = set()

        for priority in ["P0", "P1", "P2"]:
            keywords = PRIORITY_KEYWORDS[priority]
            for idx, item in enumerate(self.items):
                if idx in assigned:
                    continue
                text = (item.get("title", "") + " " + item.get("description", "")).lower()
                if any(kw in text for kw in keywords):
                    result[priority].append(item)
                    assigned.add(idx)

        return result

    def generate_distribution_chart(self) -> str:
        """Generate an ASCII bar chart showing issue distribution.

        Returns empty string if fewer than 5 items.
        """
        if len(self.items) < 5:
            return ""

        top_themes = self.get_top_themes()
        if not top_themes:
            return ""

        total = sum(count for _, _, _, count in top_themes)
        if total == 0:
            return ""

        lines = ["## Ïù¥Ïäà Î∂ÑÌè¨ ÌòÑÌô©\n", "```"]
        max_name_len = max(len(name) for name, _, _, _ in top_themes)

        for name, _key, _emoji, count in top_themes:
            pct = count / max(len(self.items), 1) * 100
            filled = int(pct / 100 * BAR_WIDTH)
            bar = "‚ñà" * filled + "‚ñë" * (BAR_WIDTH - filled)
            lines.append(f"{name:<{max_name_len}}  {bar}  {pct:4.0f}%  ({count}Í±¥)")

        lines.append("```")
        lines.append(f"\n*Ï¥ù {len(self.items)}Í±¥Ïùò Îâ¥Ïä§ ÏàòÏßë ÏôÑÎ£å*")
        return "\n".join(lines)

    def generate_themed_news_sections(self, max_articles: int = ARTICLES_PER_THEME,
                                      featured_count: int = 3) -> str:
        """Generate theme-based news sections with description cards.

        Top articles per theme include description summaries in card format.
        Remaining articles are shown in a collapsed list.
        Returns empty string if fewer than 5 items.

        Args:
            max_articles: Maximum total articles to show per theme.
            featured_count: Number of articles to show with full description.
        """
        if len(self.items) < 5:
            return ""

        top_themes = self.get_top_themes()
        if not top_themes:
            return ""

        lines = ["## Ïπ¥ÌÖåÍ≥†Î¶¨Î≥Ñ Ï£ºÏöî Îâ¥Ïä§\n"]

        for name, key, emoji, count in top_themes:
            articles = self._theme_articles.get(key, [])
            # Theme briefing
            briefing = self._generate_single_theme_briefing(key, articles)
            lines.append(f"### {emoji} {name} ({count}Í±¥)\n")
            if briefing:
                lines.append(f"> {briefing}\n")

            shown = 0
            seen_titles: set = set()
            remaining = []
            for article in articles:
                title = article.get("title", "")
                if not title or title in seen_titles:
                    continue
                seen_titles.add(title)
                link = article.get("link", "")
                source = article.get("source", "")
                description = article.get("description", "").strip()

                if shown < featured_count:
                    # Featured card with description
                    if link:
                        lines.append(f"**{shown + 1}. [{title}]({link})**")
                    else:
                        lines.append(f"**{shown + 1}. {title}**")
                    if description and description != title:
                        # Truncate description to 150 chars
                        desc_text = description[:150]
                        if len(description) > 150:
                            desc_text += "..."
                        lines.append(f"{desc_text}")
                    lines.append(f"`Ï∂úÏ≤ò: {source}`\n")
                else:
                    # Remaining items collected for collapsed list
                    if link:
                        remaining.append(f"[{title}]({link})")
                    else:
                        remaining.append(title)

                shown += 1
                if shown >= max_articles:
                    break

            # Show remaining as collapsed list
            overflow = len([a for a in articles if a.get("title") and a["title"] not in seen_titles])
            remaining_count = len(remaining) + overflow
            if remaining:
                remaining_str = ", ".join(remaining[:7])
                if remaining_count > 7:
                    remaining_str += f" Ïô∏ {remaining_count - 7}Í±¥"
                lines.append(f"> Í∑∏ Ïô∏ {remaining_count}Í±¥: {remaining_str}\n")

            lines.append("")

        return "\n".join(lines)

    # Stop words to exclude from theme briefing keywords
    _STOP_WORDS = {
        # English
        "stock", "market", "today", "will", "this", "that", "with", "from",
        "have", "been", "were", "what", "when", "where", "which", "while",
        "more", "than", "also", "just", "into", "over", "some", "most",
        "here", "they", "their", "them", "there", "these", "those",
        "about", "after", "before", "could", "would", "should", "other",
        "news", "says", "said", "like", "amid", "near", "latest", "first",
        "last", "next", "week", "year", "days", "time", "back", "still",
        "even", "very", "much", "many", "each", "every", "make", "made",
        "does", "know", "take", "come", "look", "show", "close", "closes",
        "gains", "little", "changed", "under", "posts", "surprise",
        "better", "despite", "price", "update", "updates", "live",
        "report", "check", "according", "report", "following", "based",
        # Korean common
        "Í¥ÄÎ†®", "Ïù¥Ïäà", "Îâ¥Ïä§", "ÏãúÏû•", "Ïò§Îäò", "ÏµúÍ∑º", "ÌòÑÏû¨",
        "Ï†ÑÏùº", "ÎåÄÎπÑ", "Î∂ÑÏïº", "Ï£ºÏöî", "Î∞©ÏïàÎ∂ÄÌÑ∞", "Ï†ÑÎßùÍπåÏßÄ", "Ï£ºÏöîÎâ¥Ïä§",
    }

    def _generate_single_theme_briefing(self, theme_key: str,
                                         articles: List[Dict[str, Any]]) -> str:
        """Generate a 1-sentence briefing for a single theme from descriptions."""
        if not articles:
            return ""

        # Collect keywords from top article descriptions
        keywords: List[str] = []
        top_desc = ""
        for article in articles[:5]:
            desc = article.get("description", "").strip()
            title = article.get("title", "")
            text = desc if desc and desc != title else title
            if not top_desc and text:
                top_desc = text[:80]
            # Extract meaningful words (4+ chars), skip stop words
            words = re.findall(r"[a-zA-ZÍ∞Ä-Ìû£]{4,}", text)
            words = [w for w in words if w.lower() not in self._STOP_WORDS]
            keywords.extend(words[:3])

        if not keywords:
            return ""

        # Get top 3 unique keywords
        kw_counts = Counter(keywords)
        top_kws = [kw for kw, _ in kw_counts.most_common(8)][:3]
        if not top_kws:
            return ""

        theme_lookup = {key: name for name, key, _, _ in THEMES}
        theme_name = theme_lookup.get(theme_key, theme_key)
        kw_str = ", ".join(top_kws)

        return f"{theme_name} Î∂ÑÏïºÏóêÏÑú {kw_str} Í¥ÄÎ†® Ïù¥ÏäàÍ∞Ä Î∂ÄÍ∞ÅÎêòÍ≥† ÏûàÏäµÎãàÎã§."

    def generate_theme_briefing(self) -> str:
        """Generate combined theme briefings for all top themes.

        Returns a section with 1-2 sentence briefings per theme,
        based on article descriptions.
        """
        if len(self.items) < 5:
            return ""

        top_themes = self.get_top_themes()
        if not top_themes:
            return ""

        lines = ["## ÌÖåÎßàÎ≥Ñ Î∏åÎ¶¨Ìïë\n"]
        has_content = False

        for name, key, emoji, count in top_themes:
            articles = self._theme_articles.get(key, [])
            briefing = self._generate_single_theme_briefing(key, articles)
            if briefing:
                lines.append(f"- {emoji} **{name}**: {briefing}")
                has_content = True

        if not has_content:
            return ""

        lines.append("")
        return "\n".join(lines)

    def generate_summary_section(self) -> str:
        """Generate a concise markdown theme summary section.

        Returns empty string if fewer than 5 items are available.
        """
        if len(self.items) < 5:
            return ""

        top_themes = self.get_top_themes()
        if not top_themes:
            return ""

        lines = ["\n## Ï£ºÏöî ÌÖåÎßà Î∂ÑÏÑù\n"]

        for name, key, emoji, count in top_themes:
            articles = self._theme_articles.get(key, [])
            lines.append(f"### {emoji} {name} ({count}Í±¥)\n")

            shown = 0
            seen_titles: set = set()
            for article in articles:
                title = article.get("title", "")
                if not title or title in seen_titles:
                    continue
                seen_titles.add(title)
                link = article.get("link", "")
                source = article.get("source", "")
                if link:
                    lines.append(f"- [{title}]({link}) ‚Äî {source}")
                else:
                    lines.append(f"- {title} ‚Äî {source}")
                shown += 1
                if shown >= 3:
                    break

            lines.append("")

        return "\n".join(lines)

    def generate_executive_summary(self, category_type: str = "general",
                                    extra_data: Dict[str, Any] | None = None) -> str:
        """Generate an enhanced TL;DR executive summary section.

        Includes 3-5 line briefing (one per theme), key points table,
        P0 urgent alerts, and market data integration.

        Args:
            category_type: One of "crypto", "stock", "regulatory", "social", "market", "security"
            extra_data: Optional dict with market data, region counts, etc.

        Returns:
            Markdown string with blockquote briefing + key points table.
        """
        if len(self.items) < 3:
            return ""

        top_themes = self.get_top_themes()
        extra = extra_data or {}
        total = len(self.items)

        # Build narrative summary
        theme_names = [t[0] for t in top_themes[:3]] if top_themes else []
        themes_str = ", ".join(theme_names[:2]) if theme_names else "Îã§ÏñëÌïú Ïù¥Ïäà"

        # Category-specific opening
        openers = {
            "crypto": f"Ïò§Îäò ÏïîÌò∏ÌôîÌèê ÏãúÏû•ÏùÄ **{themes_str}** Ï§ëÏã¨ÏúºÎ°ú {total}Í±¥Ïùò Îâ¥Ïä§Í∞Ä ÏàòÏßëÎêòÏóàÏäµÎãàÎã§.",
            "stock": f"Ïò§Îäò Ï£ºÏãù ÏãúÏû•ÏùÄ **{themes_str}** Ïù¥ÏäàÍ∞Ä Î∂ÄÍ∞ÅÎêòÎ©∞ {total}Í±¥Ïùò Îâ¥Ïä§Í∞Ä Î∂ÑÏÑùÎêòÏóàÏäµÎãàÎã§.",
            "regulatory": f"Í∏ÄÎ°úÎ≤å Í∑úÏ†ú ÎèôÌñ•ÏóêÏÑú **{themes_str}** Í¥ÄÎ†® {total}Í±¥Ïùò ÏÜåÏãùÏù¥ ÏàòÏßëÎêòÏóàÏäµÎãàÎã§.",
            "social": f"ÏÜåÏÖú ÎØ∏ÎîîÏñ¥ÏóêÏÑú **{themes_str}** Í¥ÄÎ†® {total}Í±¥Ïùò Ìä∏Î†åÎìúÍ∞Ä Ìè¨Ï∞©ÎêòÏóàÏäµÎãàÎã§.",
            "security": f"Î∏îÎ°ùÏ≤¥Ïù∏ Î≥¥Ïïà Î∂ÑÏïºÏóêÏÑú {total}Í±¥Ïùò ÏÇ¨Í±¥Ïù¥ Î≥¥Í≥†ÎêòÏóàÏäµÎãàÎã§.",
            "market": f"ÏãúÏû• Ï†ÑÎ∞òÏóê Í±∏Ï≥ê **{themes_str}** Ïù¥ÏäàÍ∞Ä Ï£ºÎèÑÌïòÍ≥† ÏûàÏäµÎãàÎã§.",
        }
        opener = openers.get(category_type, f"Ï¥ù {total}Í±¥Ïùò Îâ¥Ïä§Í∞Ä ÏàòÏßëÎêòÏóàÏäµÎãàÎã§. **{themes_str}** Í¥ÄÎ†® Ïù¥ÏäàÍ∞Ä Ï£ºÎ™©Îê©ÎãàÎã§.")

        lines = ["\n## ÌïúÎààÏóê Î≥¥Í∏∞\n"]
        lines.append(f"> {opener}\n")

        # Multi-line briefing: one line per top theme
        briefing_lines = []
        for name, key, emoji, count in top_themes[:4]:
            articles = self._theme_articles.get(key, [])
            if not articles:
                continue
            # Pick the top article description
            top_desc = ""
            for art in articles[:3]:
                desc = art.get("description", "").strip()
                title = art.get("title", "")
                if desc and desc != title and len(desc) > 20:
                    top_desc = desc[:100]
                    if len(desc) > 100:
                        top_desc += "..."
                    break
            if top_desc:
                briefing_lines.append(f"> - {emoji} **{name}** ({count}Í±¥): {top_desc}")
            else:
                briefing_lines.append(f"> - {emoji} **{name}**: {count}Í±¥Ïùò Í¥ÄÎ†® Îâ¥Ïä§Í∞Ä ÏàòÏßëÎêòÏóàÏäµÎãàÎã§.")

        if briefing_lines:
            lines.extend(briefing_lines)
            lines.append("")

        # P0 urgent alerts inline
        priority_items = self.classify_priority()
        if priority_items.get("P0"):
            p0_titles = [item.get("title", "") for item in priority_items["P0"][:3]]
            if p0_titles:
                lines.append(f"> **Í∏¥Í∏â**: {', '.join(p0_titles[:2])}")
                lines.append("")

        # Key points table
        lines.append("| Íµ¨Î∂Ñ | ÎÇ¥Ïö© |")
        lines.append("|------|------|")
        lines.append(f"| ÏàòÏßë Í±¥Ïàò | {total}Í±¥ |")

        if theme_names:
            lines.append(f"| Ï£ºÏöî ÌÖåÎßà | {', '.join(theme_names)} |")

        # Add theme article counts
        if top_themes:
            top_theme = top_themes[0]
            lines.append(f"| ÏµúÎã§ Ïù¥Ïäà | {top_theme[2]} {top_theme[0]} ({top_theme[3]}Í±¥) |")

        # Category-specific extra rows
        if category_type == "stock" and extra.get("kr_market"):
            kr = extra["kr_market"]
            for name, info in kr.items():
                lines.append(f"| {name} | {info['price']} ({info['change_pct']}) |")

        if category_type == "regulatory" and extra.get("region_counts"):
            regions = extra["region_counts"]
            region_str = ", ".join(f"{r} {c}Í±¥" for r, c in regions.most_common())
            lines.append(f"| ÏßÄÏó≠Î≥Ñ | {region_str} |")

        if category_type == "social" and extra.get("top_keywords"):
            kw_str = ", ".join(f"{kw}({cnt})" for kw, cnt in extra["top_keywords"][:5])
            lines.append(f"| Ìï´ ÌÇ§ÏõåÎìú | {kw_str} |")

        if category_type == "crypto" and extra.get("top_keywords"):
            kw_str = ", ".join(f"{kw}({cnt})" for kw, cnt in extra["top_keywords"][:5])
            lines.append(f"| Ìï´ ÌÇ§ÏõåÎìú | {kw_str} |")

        lines.append("")
        return "\n".join(lines)
