"""Keyword-based theme summarizer for collected news items.

Classifies news items into predefined themes using keyword matching
and generates markdown summary sections including:
- Issue distribution ASCII bar chart
- Theme-based news grouping with articles per theme
- Top keyword analysis

No LLM or external dependencies required.
"""

import re
import logging
from collections import Counter
from typing import List, Dict, Any, Tuple

logger = logging.getLogger(__name__)

# Theme definitions: (theme_name_ko, theme_key, emoji, keywords)
THEMES = [
    ("ê·œì œ/ì •ì±…", "regulation", "ğŸ”µ", [
        "sec", "cftc", "fca", "regulation", "regulatory", "compliance",
        "ê·œì œ", "ê¸ˆìœµìœ„", "ê¸ˆê°ì›", "mica", "esma", "mas", "ë²•ì•ˆ", "bill",
        "enforcement", "lawsuit", "ì†Œì†¡", "ì œì¬",
    ]),
    ("DeFi", "defi", "ğŸŸ£", [
        "defi", "dex", "yield", "lending", "tvl", "liquidity",
        "aave", "uniswap", "compound", "staking",
        "restaking", "bridge", "swap", "pool", "vault",
    ]),
    ("ë¹„íŠ¸ì½”ì¸", "bitcoin", "ğŸŸ ", [
        "bitcoin", "btc", "mining", "halving", "ë¹„íŠ¸ì½”ì¸", "ì±„êµ´",
        "satoshi", "lightning network",
        "ordinals", "runes", "etf",
    ]),
    ("ì´ë”ë¦¬ì›€", "ethereum", "ğŸ”·", [
        "ethereum", "eth", "layer2", "rollup", "ì´ë”ë¦¬ì›€",
        "solidity", "evm", "l2",
        "blob", "dencun", "arbitrum", "optimism", "base", "zksync",
    ]),
    ("AI/ê¸°ìˆ ", "ai_tech", "ğŸ¤–", [
        "ai", "artificial intelligence", "gpu", "ì¸ê³µì§€ëŠ¥",
        "machine learning", "chatgpt", "nvidia", "ë°˜ë„ì²´",
        "ì—”ë¹„ë””ì•„", "í…ŒìŠ¬ë¼", "ì• í”Œ", "ë§ˆì´í¬ë¡œì†Œí”„íŠ¸", "êµ¬ê¸€",
        "openai", "anthropic", "semiconductor", "tsmc",
    ]),
    ("ë§¤í¬ë¡œ/ê¸ˆë¦¬", "macro", "ğŸ“Š", [
        "fed", "interest rate", "inflation", "ê¸ˆë¦¬", "í•œêµ­ì€í–‰",
        "gdp", "cpi", "fomc", "rate cut", "rate hike", "í™˜ìœ¨",
        "ë¬¼ê°€", "ì‹¤ì—…ë¥ ", "ê³ ìš©", "ì†Œë¹„ìë¬¼ê°€", "pce",
        "ê¸°ì¤€ê¸ˆë¦¬", "ì–‘ì ì™„í™”", "ì–‘ì ê¸´ì¶•", "treasury", "ì±„ê¶Œ",
    ]),
    ("ê±°ë˜ì†Œ", "exchange", "ğŸ¦", [
        "binance", "coinbase", "exchange", "listing", "ê±°ë˜ì†Œ",
        "upbit", "bithumb", "bybit", "okx",
        "kraken", "ìƒì¥", "ìƒì¥íì§€", "delisting",
    ]),
    ("ë³´ì•ˆ/í•´í‚¹", "security", "ğŸ”´", [
        "hack", "exploit", "vulnerability", "security", "í•´í‚¹",
        "breach", "phishing", "scam", "rug pull",
        "drain", "flash loan", "oracle", "ì¬ì§„ì…",
    ]),
    ("ì •ì¹˜/ì •ì±…", "politics", "ğŸ›ï¸", [
        "trump", "ì´ì¬ëª…", "election", "policy", "ì •ì±…",
        "tariff", "sanction", "congress", "ì˜íšŒ", "ê´€ì„¸",
        "ë°±ì•…ê´€", "ëŒ€í†µë ¹", "executive order", "í–‰ì •ëª…ë ¹",
    ]),
    ("NFT/Web3", "nft_web3", "ğŸ¨", [
        "nft", "metaverse", "web3", "opensea", "ë©”íƒ€ë²„ìŠ¤",
        "digital collectible",
        "gamefi", "socialfi", "creator",
    ]),
    ("ê°€ê²©/ì‹œì¥", "price_market", "ğŸ“ˆ", [
        "price", "rally", "crash", "surge", "plunge", "ì‹œì„¸",
        "ìƒìŠ¹", "í•˜ë½", "ê¸‰ë“±", "ê¸‰ë½", "í­ë½", "ë°˜ë“±",
        "bull", "bear", "bullish", "bearish", "ê°•ì„¸", "ì•½ì„¸",
        "ì¡°ì •", "correction", "ì½”ìŠ¤í”¼", "ì½”ìŠ¤ë‹¥", "ë‚˜ìŠ¤ë‹¥",
        "ë‹¤ìš°ì¡´ìŠ¤", "ê¸ˆ", "ì›ìœ ", "ë‹¬ëŸ¬",
    ]),
]

TOP_THEMES_COUNT = 5
ARTICLES_PER_THEME = 5
BAR_WIDTH = 18


class ThemeSummarizer:
    """Classify news items into themes and generate markdown summary sections."""

    def __init__(self, items: List[Dict[str, Any]]):
        self.items = items
        self._theme_scores: Dict[str, int] = {}
        self._theme_articles: Dict[str, List[Dict[str, Any]]] = {}
        self._scored = False

    def _ensure_scored(self):
        """Score themes lazily on first access."""
        if self._scored:
            return
        self._score_themes()
        self._scored = True

    def _score_themes(self):
        """Score each theme by keyword frequency across all items."""
        all_text = " ".join(
            (item.get("title", "") + " " + item.get("description", ""))
            for item in self.items
        ).lower()

        token_freq = Counter(re.findall(r"[a-zê°€-í£]+", all_text))

        for theme_name, theme_key, _emoji, keywords in THEMES:
            score = sum(token_freq.get(kw, 0) for kw in keywords)
            for kw in keywords:
                if " " in kw:
                    score += all_text.count(kw)
            self._theme_scores[theme_key] = score

        # Match articles to themes (each article to its best-matching theme)
        article_assigned: Dict[int, str] = {}
        for theme_name, theme_key, _emoji, keywords in THEMES:
            matched = []
            kw_set = set(keywords)
            for idx, item in enumerate(self.items):
                item_text = (item.get("title", "") + " " + item.get("description", "")).lower()
                if any(kw in item_text for kw in kw_set):
                    matched.append(item)
                    if idx not in article_assigned:
                        article_assigned[idx] = theme_key
            self._theme_articles[theme_key] = matched

    def get_top_themes(self) -> List[Tuple[str, str, str, int]]:
        """Return top themes as (name, key, emoji, article_count) tuples."""
        self._ensure_scored()
        theme_lookup = {key: (name, emoji) for name, key, emoji, _ in THEMES}
        ranked = sorted(self._theme_scores.items(), key=lambda x: x[1], reverse=True)
        result = []
        for key, score in ranked:
            if score <= 0:
                continue
            name, emoji = theme_lookup.get(key, (key, ""))
            count = len(self._theme_articles.get(key, []))
            if count > 0:
                result.append((name, key, emoji, count))
            if len(result) >= TOP_THEMES_COUNT:
                break
        return result

    def generate_distribution_chart(self) -> str:
        """Generate an ASCII bar chart showing issue distribution.

        Returns empty string if fewer than 5 items.
        """
        if len(self.items) < 5:
            return ""

        top_themes = self.get_top_themes()
        if not top_themes:
            return ""

        total = sum(count for _, _, _, count in top_themes)
        if total == 0:
            return ""

        lines = ["## ì´ìŠˆ ë¶„í¬ í˜„í™©\n", "```"]
        max_name_len = max(len(name) for name, _, _, _ in top_themes)

        for name, _key, _emoji, count in top_themes:
            pct = count / max(len(self.items), 1) * 100
            filled = int(pct / 100 * BAR_WIDTH)
            bar = "â–ˆ" * filled + "â–‘" * (BAR_WIDTH - filled)
            lines.append(f"{name:<{max_name_len}}  {bar}  {pct:4.0f}%  ({count}ê±´)")

        lines.append("```")
        lines.append(f"\n*ì´ {len(self.items)}ê±´ì˜ ë‰´ìŠ¤ ìˆ˜ì§‘ ì™„ë£Œ*")
        return "\n".join(lines)

    def generate_themed_news_sections(self, max_articles: int = ARTICLES_PER_THEME) -> str:
        """Generate theme-based news sections with tables.

        Each theme gets its own subsection with a news table.
        Returns empty string if fewer than 5 items.
        """
        if len(self.items) < 5:
            return ""

        top_themes = self.get_top_themes()
        if not top_themes:
            return ""

        lines = ["## ì¹´í…Œê³ ë¦¬ë³„ ì£¼ìš” ë‰´ìŠ¤\n"]

        for name, key, emoji, count in top_themes:
            articles = self._theme_articles.get(key, [])
            lines.append(f"### {emoji} {name} ({count}ê±´)\n")
            lines.append("| ì œëª© | ì¶œì²˜ |")
            lines.append("|------|------|")

            shown = 0
            seen_titles: set = set()
            for article in articles:
                title = article.get("title", "")
                if not title or title in seen_titles:
                    continue
                seen_titles.add(title)
                link = article.get("link", "")
                source = article.get("source", "")
                if link:
                    lines.append(f"| [{title}]({link}) | {source} |")
                else:
                    lines.append(f"| {title} | {source} |")
                shown += 1
                if shown >= max_articles:
                    break

            lines.append("")

        return "\n".join(lines)

    def generate_summary_section(self) -> str:
        """Generate a concise markdown theme summary section.

        Returns empty string if fewer than 5 items are available.
        """
        if len(self.items) < 5:
            return ""

        top_themes = self.get_top_themes()
        if not top_themes:
            return ""

        lines = ["\n## ì£¼ìš” í…Œë§ˆ ë¶„ì„\n"]

        for name, key, emoji, count in top_themes:
            articles = self._theme_articles.get(key, [])
            lines.append(f"### {emoji} {name} ({count}ê±´)\n")

            shown = 0
            seen_titles: set = set()
            for article in articles:
                title = article.get("title", "")
                if not title or title in seen_titles:
                    continue
                seen_titles.add(title)
                link = article.get("link", "")
                source = article.get("source", "")
                if link:
                    lines.append(f"- [{title}]({link}) â€” {source}")
                else:
                    lines.append(f"- {title} â€” {source}")
                shown += 1
                if shown >= 3:
                    break

            lines.append("")

        return "\n".join(lines)

    def generate_executive_summary(self, category_type: str = "general",
                                    extra_data: Dict[str, Any] | None = None) -> str:
        """Generate a TL;DR executive summary section for the top of blog posts.

        Args:
            category_type: One of "crypto", "stock", "regulatory", "social", "market", "security"
            extra_data: Optional dict with market data, region counts, etc.

        Returns:
            Markdown string with blockquote summary + key points table.
        """
        if len(self.items) < 3:
            return ""

        top_themes = self.get_top_themes()
        extra = extra_data or {}
        total = len(self.items)

        # Build narrative summary
        theme_names = [t[0] for t in top_themes[:3]] if top_themes else []
        themes_str = ", ".join(theme_names[:2]) if theme_names else "ë‹¤ì–‘í•œ ì´ìŠˆ"

        # Category-specific opening
        openers = {
            "crypto": f"ì˜¤ëŠ˜ ì•”í˜¸í™”í ì‹œì¥ì€ **{themes_str}** ì¤‘ì‹¬ìœ¼ë¡œ {total}ê±´ì˜ ë‰´ìŠ¤ê°€ ìˆ˜ì§‘ë˜ì—ˆìŠµë‹ˆë‹¤.",
            "stock": f"ì˜¤ëŠ˜ ì£¼ì‹ ì‹œì¥ì€ **{themes_str}** ì´ìŠˆê°€ ë¶€ê°ë˜ë©° {total}ê±´ì˜ ë‰´ìŠ¤ê°€ ë¶„ì„ë˜ì—ˆìŠµë‹ˆë‹¤.",
            "regulatory": f"ê¸€ë¡œë²Œ ê·œì œ ë™í–¥ì—ì„œ **{themes_str}** ê´€ë ¨ {total}ê±´ì˜ ì†Œì‹ì´ ìˆ˜ì§‘ë˜ì—ˆìŠµë‹ˆë‹¤.",
            "social": f"ì†Œì…œ ë¯¸ë””ì–´ì—ì„œ **{themes_str}** ê´€ë ¨ {total}ê±´ì˜ íŠ¸ë Œë“œê°€ í¬ì°©ë˜ì—ˆìŠµë‹ˆë‹¤.",
            "security": f"ë¸”ë¡ì²´ì¸ ë³´ì•ˆ ë¶„ì•¼ì—ì„œ {total}ê±´ì˜ ì‚¬ê±´ì´ ë³´ê³ ë˜ì—ˆìŠµë‹ˆë‹¤.",
            "market": f"ì‹œì¥ ì „ë°˜ì— ê±¸ì³ **{themes_str}** ì´ìŠˆê°€ ì£¼ë„í•˜ê³  ìˆìŠµë‹ˆë‹¤.",
        }
        opener = openers.get(category_type, f"ì´ {total}ê±´ì˜ ë‰´ìŠ¤ê°€ ìˆ˜ì§‘ë˜ì—ˆìŠµë‹ˆë‹¤. **{themes_str}** ê´€ë ¨ ì´ìŠˆê°€ ì£¼ëª©ë©ë‹ˆë‹¤.")

        lines = ["\n## í•œëˆˆì— ë³´ê¸°\n"]
        lines.append(f"> {opener}\n")

        # Key points table
        lines.append("| êµ¬ë¶„ | ë‚´ìš© |")
        lines.append("|------|------|")
        lines.append(f"| ìˆ˜ì§‘ ê±´ìˆ˜ | {total}ê±´ |")

        if theme_names:
            lines.append(f"| ì£¼ìš” í…Œë§ˆ | {', '.join(theme_names)} |")

        # Add theme article counts
        if top_themes:
            top_theme = top_themes[0]
            lines.append(f"| ìµœë‹¤ ì´ìŠˆ | {top_theme[2]} {top_theme[0]} ({top_theme[3]}ê±´) |")

        # Category-specific extra rows
        if category_type == "stock" and extra.get("kr_market"):
            kr = extra["kr_market"]
            for name, info in kr.items():
                lines.append(f"| {name} | {info['price']} ({info['change_pct']}) |")

        if category_type == "regulatory" and extra.get("region_counts"):
            regions = extra["region_counts"]
            region_str = ", ".join(f"{r} {c}ê±´" for r, c in regions.most_common())
            lines.append(f"| ì§€ì—­ë³„ | {region_str} |")

        if category_type == "social" and extra.get("top_keywords"):
            kw_str = ", ".join(f"{kw}({cnt})" for kw, cnt in extra["top_keywords"][:5])
            lines.append(f"| í•« í‚¤ì›Œë“œ | {kw_str} |")

        if category_type == "crypto" and extra.get("top_keywords"):
            kw_str = ", ".join(f"{kw}({cnt})" for kw, cnt in extra["top_keywords"][:5])
            lines.append(f"| í•« í‚¤ì›Œë“œ | {kw_str} |")

        lines.append("")
        return "\n".join(lines)
